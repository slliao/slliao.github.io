---
title: "Story: no one knows what entropy really is"
categories: [Random, Scientists]
tags: [Entropy,  Shannon, John von Neumann]
---

In the case of Shannon's measure the naming was not accidental. In 1961 one of us (Tribus) asked Shannon what he had thought about when he had finally confirmed his famous measure. Shannon replied: "My greatest concern was what to call it. I thought of calling it 'information,' but the word was overly used, so I decided to call it 'uncertainty.' When I discussed it with John von Neumann, he had a better idea. Von Neumann told me, 'You should call it entropy, for two reasons. In the first place your uncertainty function has been used in statistical mechanics under that name, so it already has a name. In the second place, and more important, no one knows what entropy really is, so in a debate you will always have the advantage.' "

Source: Tribus, Myron aria vicIrving, Edward C. (1971). "Energy and Information", Scientific American, 225: 179-88.
